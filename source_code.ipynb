{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program aims to find local influencers in an undirected social network,\n",
    "regardless human or animal.\n",
    "The program is composed of two modules:\n",
    "\n",
    "1. Graph clustering.\n",
    "\n",
    "Splits the social network into several dense subgraphs, which\n",
    "represent a community.\n",
    "The strategies used are Markov clustering and spectral clustering.\n",
    "\n",
    "2. Finding the most influental user in a community\n",
    "\n",
    "The most influental user is defined by the user with the highest centrality.\n",
    "The measures of centrality used are eigenvector centrality, \n",
    "degree centrality and closeness centrality. \n",
    "\n",
    "Therefore, this project is a survey of\n",
    "some density based clustering methods\n",
    "and centrality measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sklearn.preprocessing\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = [\n",
    "    r'.\\datasets\\karate\\karate-club.csv',\n",
    "    r'.\\datasets\\soc-dolphins\\soc-dolphins.csv',\n",
    "    r'.\\datasets\\aves-wildbird-network-3\\aves-wildbird-network-3.csv',\n",
    "    r'.\\datasets\\aves-wildbird-network\\aves-wildbird-network.csv',\n",
    "    r'.\\datasets\\ca-netscience\\ca-netscience.csv',\n",
    "    r'.\\datasets\\soc-wiki-Vote\\soc-wiki-Vote.csv',\n",
    "]\n",
    "\n",
    "nx_graph = []\n",
    "\n",
    "for i in range(len(data_source)):\n",
    "    dat = pd.read_csv(data_source[i])\n",
    "    n1 = dat['node_1'].to_numpy()\n",
    "    n2 = dat['node_2'].to_numpy()\n",
    "\n",
    "    gra = dgl.graph((n1, n2))\n",
    "    nx_graph.append(gra.to_networkx().to_undirected())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the Markov clustering method will be performed on the graph.\n",
    "This uses a random walk technique, which is itself a Markov chain, to identify clusters.\n",
    "\n",
    "It is observed that for an undirected and unweighted graph, nodes of higher degree are less likely \n",
    "to have edges with nodes in another cluster.\n",
    "\n",
    "First, we construct the adjacency matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiGraph with 35 nodes and 78 edges\n",
      "MultiGraph with 63 nodes and 159 edges\n",
      "MultiGraph with 170 nodes and 1615 edges\n",
      "MultiGraph with 203 nodes and 11780 edges\n",
      "MultiGraph with 380 nodes and 914 edges\n",
      "MultiGraph with 890 nodes and 2914 edges\n"
     ]
    }
   ],
   "source": [
    "matrix = nx.to_scipy_sparse_array(nx_graph[2])\n",
    "for i in range(0, 6):\n",
    "    print(nx_graph[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Markov clustering algorithm takes in a normalized matrix, an inflation factor and an expansion factor.\n",
    "\n",
    "The expansion factor is the length of a random walk, while the inflation factor is\n",
    "directly correlated to the number of clusters.\n",
    "\n",
    "It directly returns the clusters.\n",
    "\n",
    "The following code uses the module from\n",
    "https://github.com/GuyAllard/markov_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markov_clustering as mc\n",
    "\n",
    "# Calculate the quality score of clusters, determined by expansion and inflation factors.\n",
    "def mc_loop(mat, exp, infl):\n",
    "    res = mc.run_mcl(mat, expansion=exp, inflation=infl)\n",
    "    clu = mc.get_clusters(res)\n",
    "\n",
    "    mod = mc.modularity(res, clu)\n",
    "    return mod\n",
    "\n",
    "# Return the best set of clusters.\n",
    "def mc_loop_final(mat, exp, infl):\n",
    "    res = mc.run_mcl(mat, expansion=exp, inflation=infl)\n",
    "    return mc.get_clusters(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Markov clustering method for the expansion factor, by increasing inflation factor.\n",
    "def mc_train(mat, expand, start, end):\n",
    "    max_infl = max_mod = 0\n",
    "\n",
    "    mod_series = []\n",
    "\n",
    "    for inflation in [i / 10 for i in range(start, end)]:\n",
    "        Q = mc_loop(mat, expand, inflation)\n",
    "        mod_series.append(Q)\n",
    "\n",
    "        if (Q > max_mod):\n",
    "            max_mod = Q\n",
    "            max_infl = inflation\n",
    "        print(f\"For expansion = {expand} inflation = {inflation}, modularity = {Q}\")\n",
    "\n",
    "    return max_infl, max_mod, mod_series\n",
    "\n",
    "# Draw the graph of modularity over inflation factors.\n",
    "def draw_graph(inflat_ser, mod_ser_exp, exp_start, exp_end):\n",
    "    i = 0\n",
    "    for c in range(exp_start, exp_end+1):\n",
    "        # print(c, i)\n",
    "        plt.plot(inflat_ser, mod_ser_exp[i], label = f'expansion factor = {c}', linestyle = \"--\")\n",
    "        i += 1\n",
    "    plt.xlabel('inflation factor')\n",
    "    plt.ylabel('modularity')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# The entire Markov clustering model.\n",
    "def markov_grand_loop(matr, expand_start, expand_end, infl_start, infl_end):\n",
    "\n",
    "    max_expand = grand_max_infl = grand_max_modularity = 0\n",
    "\n",
    "    inflation_series = range(infl_start, infl_end)\n",
    "    inflation_series = [inf / 10 for inf in inflation_series]\n",
    "\n",
    "    mod_ser_by_expansion = []\n",
    "\n",
    "    for i in range(expand_start, expand_end+1):\n",
    "\n",
    "        curr_max_infl, curr_max_mod, mod_ser = mc_train(matr, i, infl_start, infl_end)\n",
    "\n",
    "        mod_ser_by_expansion.append(mod_ser)\n",
    "\n",
    "        if grand_max_modularity < curr_max_mod:\n",
    "            max_expand = i\n",
    "            grand_max_infl = curr_max_infl\n",
    "            grand_max_modularity = curr_max_mod\n",
    "        \n",
    "        # print(max_expand, grand_max_infl,  grand_max_modularity)\n",
    "    \n",
    "    draw_graph(inflation_series, mod_ser_by_expansion, expand_start, expand_end)\n",
    "\n",
    "    final_cluster = mc_loop_final(matr, max_expand, grand_max_infl)\n",
    "    return final_cluster\n",
    "\n",
    "# Return the list of clusters.\n",
    "def final_clean(clust):\n",
    "    cl = []\n",
    "    for i in range(len(clust)):\n",
    "        lis = list(clust[i])\n",
    "        cl.append(lis)\n",
    "    return cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we explore another method which is the spectral clustering.\n",
    "It uses the graph Laplacian and some of its eigenvectors to identify\n",
    "dense clusters.\n",
    "\n",
    "To find these clusters, we need to use a classical clustering method,\n",
    "such as the k-means clustering.\n",
    "\n",
    "First we construct a graph Laplacian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(G):\n",
    "    return nx.laplacian_matrix(G).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform spectral clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "#The spectral clustering method using a k-means method:\n",
    "def spectral(G, n = 3):\n",
    "    lap = laplacian(G)\n",
    "    eigenvals, eigenvecs = np.linalg.eig(lap)\n",
    "\n",
    "    eigenvecs = eigenvecs[:,np.argsort(eigenvals)]\n",
    "    eigenvals = eigenvals[np.argsort(eigenvals)]\n",
    "\n",
    "    km = KMeans(n)\n",
    "    km.fit(eigenvecs[:,1:n])\n",
    "    labels = km.labels_.tolist()\n",
    "\n",
    "    node_no = list(range(1, G.number_of_nodes() + 1))\n",
    "    node_no = np.array(node_no).tolist()\n",
    "\n",
    "    node_and_label = dict(zip(node_no, labels))\n",
    "\n",
    "    return node_and_label\n",
    "\n",
    "#With K-medoid method \n",
    "def spectral_2(G, n = 3):\n",
    "    lap = laplacian(G)\n",
    "    eigenvals, eigenvecs = np.linalg.eig(lap)\n",
    "\n",
    "    eigenvecs = eigenvecs[:,np.argsort(eigenvals)]\n",
    "    eigenvals = eigenvals[np.argsort(eigenvals)]\n",
    "\n",
    "    km = KMedoids(n_clusters=n).fit(eigenvecs[:,1:n])\n",
    "    labels = km.labels_.tolist()\n",
    "\n",
    "    node_no = list(range(1, G.number_of_nodes() + 1))\n",
    "    node_no = np.array(node_no).tolist()\n",
    "\n",
    "    node_and_label = dict(zip(node_no, labels))\n",
    "\n",
    "    return node_and_label\n",
    "\n",
    "'''\n",
    "def spec_train(G, start, end):\n",
    "    for x in range(start, end+1):\n",
    "        lab = spectral(G, n = x)\n",
    "'''\n",
    "# Return the list of clusters from spectral clustering.    \n",
    "def spectral_post_process(n, node_and_labl):\n",
    "    clusters = []\n",
    "    for i in range(n):\n",
    "        clusters.append([])\n",
    "    for j in node_and_labl:\n",
    "        clusters[node_and_labl.get(j)].append(j)\n",
    "    return clusters\n",
    "\n",
    "#Calculate the skewedness of clusters. The higher the number,\n",
    "# the more unbalanced the clusters.\n",
    "def balance_score_clusters(clust):\n",
    "    num_of_node_in_cluster = []\n",
    "    for a in clust:\n",
    "        num_of_node_in_cluster.append(len(a))\n",
    "    return statistics.stdev(num_of_node_in_cluster)\n",
    "\n",
    "#The entire spectral clustering model.\n",
    "def spectral_grand_loop(graph, k_start, k_end):\n",
    "\n",
    "    k_m = []\n",
    "    dev_soc = []\n",
    "\n",
    "    min_std_dev = 99999\n",
    "\n",
    "    for r in range(k_start, k_end+1):\n",
    "\n",
    "        k_m.append(r)\n",
    "\n",
    "        print(r)\n",
    "\n",
    "        pre_cluster = spectral_2(graph, r)\n",
    "        fin_cluster = spectral_post_process(r, pre_cluster)\n",
    "        dev_score = balance_score_clusters(fin_cluster)\n",
    "\n",
    "        if dev_score < min_std_dev:\n",
    "            min_std_dev = dev_score\n",
    "\n",
    "        dev_soc.append(dev_score)\n",
    "        # print(f\"For k = {r}, the standard deviation for clusters is {dev_score}\")\n",
    "    \n",
    "    plt.plot(k_m, dev_soc, linestyle=\"--\")\n",
    "    plt.xlabel(\"k as in k-means/k-medoid clustering\")\n",
    "    plt.ylabel(\"standard deviation of clustering labels\")\n",
    "    plt.show()\n",
    "    \n",
    "    best_k = k_m[ dev_soc.index(min_std_dev) ]\n",
    "\n",
    "    best_pre_cluster = spectral(graph, best_k)\n",
    "    return spectral_post_process(best_k, best_pre_cluster)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test the Louvain community detection algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def louvain_algo(G):\n",
    "    return nx.algorithms.community.louvain_communities(G, resolution = 0.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we place the nodes into clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_communities(Dgraph, communities):\n",
    "    comm = []\n",
    "    for i in communities:\n",
    "        if len(i) <= 4:\n",
    "            continue\n",
    "        else:\n",
    "            # print(i)\n",
    "            co = Dgraph.subgraph(i)\n",
    "            comm.append(co)\n",
    "    return comm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the disjoint clusters ready,\n",
    "we can calculate the centrality of each node in each subgraph.\n",
    "The measures of centrality used are eigencentrality, degree centrality and\n",
    "closeness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close centrality of a graph\n",
    "def close_centrality(G, lst):\n",
    "    centr = nx.closeness_centrality(G)\n",
    "    sorted_centr = sorted(centr.items(), key = lambda centr: centr[1])\n",
    "\n",
    "    sorted_centr.reverse()\n",
    "    # print(sorted_centr)\n",
    "\n",
    "    lst.append(sorted_centr[0][0])\n",
    "\n",
    "#Eigencentrality of a graph\n",
    "def eigencentrality(G, lst):\n",
    "    g2 = nx.DiGraph(G)\n",
    "    ctr = nx.eigenvector_centrality(g2)\n",
    "\n",
    "    sorted_ctr = sorted(ctr.items(), key = lambda ctr: ctr[1])\n",
    "    sorted_ctr.reverse()\n",
    "    # print(sorted_ctr)\n",
    "\n",
    "    lst.append(sorted_ctr[0][0])\n",
    "\n",
    "#Degree centrality of a graph\n",
    "def degree_centrality(G, lst):\n",
    "    ctr = nx.degree_centrality(G)\n",
    "\n",
    "    sorted_ctr = sorted(ctr.items(), key = lambda ctr: ctr[1])\n",
    "    sorted_ctr.reverse()\n",
    "    # print(sorted_ctr)\n",
    "\n",
    "    lst.append(sorted_ctr[0][0])\n",
    "\n",
    "#Identify list of influencers in each community in a graph\n",
    "def create_list_of_local_influencers(communi, mode):\n",
    "    influencer_list = []\n",
    "    for com in communi:\n",
    "        if mode == 1:\n",
    "            degree_centrality(com, influencer_list)\n",
    "        if mode == 2:\n",
    "            close_centrality(com, influencer_list)\n",
    "        if mode == 3:\n",
    "            eigencentrality(com, influencer_list)\n",
    "    return influencer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of influencers in dataset 6: [8, 123, 389, 542, 170, 273, 550, 657, 762, 376]\n"
     ]
    }
   ],
   "source": [
    "def markov_test():\n",
    "    i = 6\n",
    "    matrix = nx.to_scipy_sparse_array(nx_graph[i-1])\n",
    "    c = markov_grand_loop(matrix, 2, 6, 11, 40)\n",
    "    final = final_clean(c)\n",
    "    communidad = separate_communities(nx_graph[i-1], final)\n",
    "    li = create_list_of_local_influencers(communidad, 3)\n",
    "    print(f\"List of influencers in dataset #{i}: {li}\")\n",
    "\n",
    "def spectral_test():\n",
    "    i = 4\n",
    "    final = spectral_grand_loop(nx_graph[i-1], 2, 20)\n",
    "    communi = separate_communities(nx_graph[i-1], final)\n",
    "    lis = create_list_of_local_influencers(communi, 3)\n",
    "    print(f\"List of influencers in dataset {i}: {lis}\")\n",
    "\n",
    "def louvain_test():\n",
    "    i = 6\n",
    "    final = louvain_algo(nx_graph[i-1])\n",
    "    communi = separate_communities(nx_graph[i-1], final)\n",
    "    lis = create_list_of_local_influencers(communi, 1)\n",
    "    print(f\"List of influencers in dataset {i}: {lis}\")\n",
    "\n",
    "louvain_test()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('COMP4222')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6101f95da5a0382018fc5350e1597ad2de59e31f36f93a2211ffb12dd5b3646"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
